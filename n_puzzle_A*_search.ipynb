{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A* Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from random import choice\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import heapq\n",
    "\n",
    "PUZZLE_DIM = 5\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])\n",
    "\n",
    "goal_state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def available_actions(state: np.ndarray) -> list['Action']:\n",
    "    x, y = [int(_[0]) for _ in np.where(state == 0)]\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state\n",
    "\n",
    "def manhattan_distance(state: np.ndarray) -> int:\n",
    "    \"\"\"Calculate the Manhattan distance heuristic for the n-puzzle.\"\"\"\n",
    "    total_distance = 0\n",
    "    for x in range(PUZZLE_DIM):\n",
    "        for y in range(PUZZLE_DIM):\n",
    "            value = state[x, y]\n",
    "            if value != 0:  # Don't compute distance for the empty tile\n",
    "                target_x, target_y = divmod(value - 1, PUZZLE_DIM)\n",
    "                total_distance += abs(target_x - x) + abs(target_y - y)\n",
    "    return total_distance\n",
    "\n",
    "def a_star(start_state: np.ndarray):\n",
    "    # Priority queue for the A* frontier\n",
    "    pq = []\n",
    "    number_of_actions_considered = 0\n",
    "    # Initial node with cost 0 and heuristic\n",
    "    start_h = manhattan_distance(start_state)\n",
    "    heapq.heappush(pq, (start_h, 0, start_state.tobytes(), []))\n",
    "    \n",
    "    # Visited states\n",
    "    visited = set()\n",
    "    visited.add(start_state.tobytes())\n",
    "    \n",
    "    while pq:\n",
    "        f, g, current_state_bytes, path = heapq.heappop(pq) \n",
    "        current_state = np.frombuffer(current_state_bytes, dtype=int).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "        \n",
    "        # Check if we reached the goal\n",
    "        if np.array_equal(current_state, goal_state):\n",
    "            return path, g, number_of_actions_considered  # Return the sequence of moves and cost\n",
    "        \n",
    "        # Generate successors\n",
    "        for act in available_actions(current_state):\n",
    "            new_state = do_action(current_state, act)\n",
    "            new_state_bytes = new_state.tobytes()\n",
    "            if new_state_bytes not in visited:\n",
    "                number_of_actions_considered += 1\n",
    "                visited.add(new_state_bytes)\n",
    "                new_g = g + 0.5 # changed from 1 to 0.5\n",
    "                new_h = manhattan_distance(new_state)\n",
    "                heapq.heappush(pq, (new_g + new_h, new_g, new_state_bytes, path + [act]))\n",
    "    \n",
    "    return None, None  # If no solution is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9febbed8b3484ec5a6aef5b892f5ddd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Randomizing:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 1149561, Quality: 84\n"
     ]
    }
   ],
   "source": [
    "# Randomize the initial state\n",
    "RANDOMIZE_STEPS = 500  \n",
    "state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "for r in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "    state = do_action(state, choice(available_actions(state)))\n",
    "\n",
    "solution_path, solution_cost,number_of_actions = a_star(state)\n",
    "print(f\"Cost: {number_of_actions}, Quality: {len(solution_path)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CI2024V2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
